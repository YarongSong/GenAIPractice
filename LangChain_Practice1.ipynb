{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58fffce02e874e709b6132e6601b41bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a2132a6567b48e3a8980f89b4a41c91",
              "IPY_MODEL_d327c394a1c74f3faaa2ec675b861385",
              "IPY_MODEL_de2fd49fd32a4a7cb305cc62c9b0a137"
            ],
            "layout": "IPY_MODEL_ec0ed66e4cf3479d929ce0003a0e37d7"
          }
        },
        "3a2132a6567b48e3a8980f89b4a41c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_975f7adf0b504f3097ed080803f38341",
            "placeholder": "​",
            "style": "IPY_MODEL_1758e1d8307d45b4a10d0f227982a8c2",
            "value": "modules.json: 100%"
          }
        },
        "d327c394a1c74f3faaa2ec675b861385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f1ceea4599c4433ba50f6e4ce2fd5dc",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0569c7e21fdb48dc87fbe20c222b9f50",
            "value": 349
          }
        },
        "de2fd49fd32a4a7cb305cc62c9b0a137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_541ab779a0c14f11980e73dc4d5f3f13",
            "placeholder": "​",
            "style": "IPY_MODEL_b4d04dda527e453880b9524d7cf0a067",
            "value": " 349/349 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "ec0ed66e4cf3479d929ce0003a0e37d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "975f7adf0b504f3097ed080803f38341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1758e1d8307d45b4a10d0f227982a8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f1ceea4599c4433ba50f6e4ce2fd5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0569c7e21fdb48dc87fbe20c222b9f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "541ab779a0c14f11980e73dc4d5f3f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4d04dda527e453880b9524d7cf0a067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f73889fe29e24e208973f64f7efa48a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82a626d87dfb4b37ac1072ebe11776fd",
              "IPY_MODEL_723031d055804215b18a799301c2b90a",
              "IPY_MODEL_9e30aee6a4c8464384843945e48a5d34"
            ],
            "layout": "IPY_MODEL_9d647eb4bbcf46e58d47ce09768c8feb"
          }
        },
        "82a626d87dfb4b37ac1072ebe11776fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369b135edf4646119f7c6305c6f41952",
            "placeholder": "​",
            "style": "IPY_MODEL_3272676949d34a5d832d4c5a8a986674",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "723031d055804215b18a799301c2b90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfab6216bfc94729bbfdca6f37a57f1a",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e72184a1c3af4f5bb989b03bde0ee7b5",
            "value": 116
          }
        },
        "9e30aee6a4c8464384843945e48a5d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15bcd4d080d3433eb1aef84af6203d08",
            "placeholder": "​",
            "style": "IPY_MODEL_25685c9c31b447e9abc0a4a8664212d3",
            "value": " 116/116 [00:00&lt;00:00, 5.93kB/s]"
          }
        },
        "9d647eb4bbcf46e58d47ce09768c8feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369b135edf4646119f7c6305c6f41952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3272676949d34a5d832d4c5a8a986674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfab6216bfc94729bbfdca6f37a57f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72184a1c3af4f5bb989b03bde0ee7b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15bcd4d080d3433eb1aef84af6203d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25685c9c31b447e9abc0a4a8664212d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb99c43b7df240968d14e8a1d6217042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfd567a09c9b44f59526a98c798de390",
              "IPY_MODEL_37971867390a42ab911d1cda8e5339f4",
              "IPY_MODEL_2bb549d4918f4943bd8657561e6ccc12"
            ],
            "layout": "IPY_MODEL_38347aa1eb9147ee93876171aa9b6f55"
          }
        },
        "cfd567a09c9b44f59526a98c798de390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_528af7db476a4dbe8606d14443951db6",
            "placeholder": "​",
            "style": "IPY_MODEL_10d64c0421b1492cac13fc2fdda2bfc7",
            "value": "README.md: 100%"
          }
        },
        "37971867390a42ab911d1cda8e5339f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ffd888b127f41ea8c34a555cba5edc9",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ae7595ad9f54ce093c01706be3100b0",
            "value": 10621
          }
        },
        "2bb549d4918f4943bd8657561e6ccc12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c558585e792e4aa1943156cb66ce3694",
            "placeholder": "​",
            "style": "IPY_MODEL_7e19f9ed891c4388996cda3367ea8952",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 444kB/s]"
          }
        },
        "38347aa1eb9147ee93876171aa9b6f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "528af7db476a4dbe8606d14443951db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d64c0421b1492cac13fc2fdda2bfc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ffd888b127f41ea8c34a555cba5edc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae7595ad9f54ce093c01706be3100b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c558585e792e4aa1943156cb66ce3694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e19f9ed891c4388996cda3367ea8952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e305a7962d984005a822103f1a540a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac0303363b2747bf941a96ef922243e9",
              "IPY_MODEL_83d7bd32d8604b22ba20c3731e9bcaa5",
              "IPY_MODEL_3ff2bdb17bf4459eb49f9b7968c482ae"
            ],
            "layout": "IPY_MODEL_03aa6c43fd1141c9b2010c794ba7379a"
          }
        },
        "ac0303363b2747bf941a96ef922243e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f37f52c0de14cb5bd81c868f3d9b834",
            "placeholder": "​",
            "style": "IPY_MODEL_f26d9ed57a494cb08fce047cc9dfdb97",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "83d7bd32d8604b22ba20c3731e9bcaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d3acbf571542c38365814c0b2d674c",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46d5d2278ee84137a8c84765438890dd",
            "value": 53
          }
        },
        "3ff2bdb17bf4459eb49f9b7968c482ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7edb3b1bd106447f901d800776fe55f9",
            "placeholder": "​",
            "style": "IPY_MODEL_4ef23d4f6bd54939a8d263e42ebe57b1",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.40kB/s]"
          }
        },
        "03aa6c43fd1141c9b2010c794ba7379a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f37f52c0de14cb5bd81c868f3d9b834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26d9ed57a494cb08fce047cc9dfdb97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d3acbf571542c38365814c0b2d674c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46d5d2278ee84137a8c84765438890dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7edb3b1bd106447f901d800776fe55f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef23d4f6bd54939a8d263e42ebe57b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a893a623f5149d6a85c064a34032b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de30de953f3b4e6cbdf0bc49f554fa29",
              "IPY_MODEL_8d42a105610d498faa1afbc37d93c2ce",
              "IPY_MODEL_752249c744954598b8a47b6a88893576"
            ],
            "layout": "IPY_MODEL_9da42afab99c40b69d9f6d0266e2709e"
          }
        },
        "de30de953f3b4e6cbdf0bc49f554fa29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1758ecdb397472eae343ca1922337e1",
            "placeholder": "​",
            "style": "IPY_MODEL_718f888a671e4218a1a0b5126400833c",
            "value": "config.json: 100%"
          }
        },
        "8d42a105610d498faa1afbc37d93c2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_814ae3a235c64fc78124461fd4913872",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_119ab87eec3f4d12a0e1ef7cc4164538",
            "value": 571
          }
        },
        "752249c744954598b8a47b6a88893576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c5c400aab194da4b7cb3738562e88a5",
            "placeholder": "​",
            "style": "IPY_MODEL_e1267694501a4d04a22504ebdadfe6e2",
            "value": " 571/571 [00:00&lt;00:00, 19.5kB/s]"
          }
        },
        "9da42afab99c40b69d9f6d0266e2709e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1758ecdb397472eae343ca1922337e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "718f888a671e4218a1a0b5126400833c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "814ae3a235c64fc78124461fd4913872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119ab87eec3f4d12a0e1ef7cc4164538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c5c400aab194da4b7cb3738562e88a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1267694501a4d04a22504ebdadfe6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "900cabeee1d64877972c3a7513c712ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a81982ff498443a91f0e32f424ae8b5",
              "IPY_MODEL_4ffac588e0a4424f9fb7bcfc585004b4",
              "IPY_MODEL_37d651be5c2442b2a02fbe4fdc740be6"
            ],
            "layout": "IPY_MODEL_500c6fd955214d5b9aa45698e5b980f5"
          }
        },
        "2a81982ff498443a91f0e32f424ae8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1afaeeda7b364c658ed2654ad3469d73",
            "placeholder": "​",
            "style": "IPY_MODEL_2858ff07f607498689433d069dda8cb5",
            "value": "model.safetensors: 100%"
          }
        },
        "4ffac588e0a4424f9fb7bcfc585004b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6732cc383a41abadec6c778f049679",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_722640f78ada4bd4a86d028a0026fcbe",
            "value": 437971872
          }
        },
        "37d651be5c2442b2a02fbe4fdc740be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d1c29b08c1746309a7e5d9bb97d75d9",
            "placeholder": "​",
            "style": "IPY_MODEL_637fab710dc94a47bce90005d5ceb7a9",
            "value": " 438M/438M [00:05&lt;00:00, 38.7MB/s]"
          }
        },
        "500c6fd955214d5b9aa45698e5b980f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1afaeeda7b364c658ed2654ad3469d73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2858ff07f607498689433d069dda8cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc6732cc383a41abadec6c778f049679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "722640f78ada4bd4a86d028a0026fcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d1c29b08c1746309a7e5d9bb97d75d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637fab710dc94a47bce90005d5ceb7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be1a063491a443079abe0b531d36c9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dfc77ef26004bbf979992c83a5c85d0",
              "IPY_MODEL_a6fc3407c87e4864abb0ace958b12221",
              "IPY_MODEL_c74a9ac5368745079c819faeb702253f"
            ],
            "layout": "IPY_MODEL_1fb0bf2bcc65498f9c6ca1561e24235f"
          }
        },
        "4dfc77ef26004bbf979992c83a5c85d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a565f5bdaf345d5b8aa515fb66f65c5",
            "placeholder": "​",
            "style": "IPY_MODEL_27d9c6c6e0c141d3bb3b4ecb17d51eed",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a6fc3407c87e4864abb0ace958b12221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d58e6869bdec41a18e1921135f0193d9",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2963c1e526164ec78405105c77c192f8",
            "value": 363
          }
        },
        "c74a9ac5368745079c819faeb702253f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6094400a00074cdfb0d70a1942c0248d",
            "placeholder": "​",
            "style": "IPY_MODEL_fa65b69d681140569de62278de13b500",
            "value": " 363/363 [00:00&lt;00:00, 16.7kB/s]"
          }
        },
        "1fb0bf2bcc65498f9c6ca1561e24235f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a565f5bdaf345d5b8aa515fb66f65c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d9c6c6e0c141d3bb3b4ecb17d51eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d58e6869bdec41a18e1921135f0193d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2963c1e526164ec78405105c77c192f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6094400a00074cdfb0d70a1942c0248d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa65b69d681140569de62278de13b500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74caff8e240442e18de5b398354dc6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_134c614c2a3d4e5db7542e127ee439d6",
              "IPY_MODEL_df8434993c02478187bc9605260f09ff",
              "IPY_MODEL_34475919c842437e8f8eba0c0db36e35"
            ],
            "layout": "IPY_MODEL_40444330d5a447628da4b47e5a889f17"
          }
        },
        "134c614c2a3d4e5db7542e127ee439d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e36ea0365e849388d1848049de4253f",
            "placeholder": "​",
            "style": "IPY_MODEL_3588c067e03d4c6ab92e54460af46651",
            "value": "vocab.txt: 100%"
          }
        },
        "df8434993c02478187bc9605260f09ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6142048ea8e3411fa28ba154257632c0",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a64d2210a7fa4fbb8a5557bcadf4712e",
            "value": 231536
          }
        },
        "34475919c842437e8f8eba0c0db36e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c7a723d63d437594493b94c4cf7f86",
            "placeholder": "​",
            "style": "IPY_MODEL_da6cf485a07a46ee91d042345abd477f",
            "value": " 232k/232k [00:00&lt;00:00, 5.35MB/s]"
          }
        },
        "40444330d5a447628da4b47e5a889f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e36ea0365e849388d1848049de4253f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3588c067e03d4c6ab92e54460af46651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6142048ea8e3411fa28ba154257632c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a64d2210a7fa4fbb8a5557bcadf4712e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64c7a723d63d437594493b94c4cf7f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6cf485a07a46ee91d042345abd477f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c1cb9130dd4029bafbbaddb0dc2bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_640e351ac55640a4a9928a67fba1bf54",
              "IPY_MODEL_415d867582ce47b3b1166d1e67cd2de7",
              "IPY_MODEL_9e1cb3cdfddb4751a66db5f453c25b12"
            ],
            "layout": "IPY_MODEL_d66cc7a6b4ce4d06bb09056433ab8bc4"
          }
        },
        "640e351ac55640a4a9928a67fba1bf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6331da87214343c19baa96eceba5bd36",
            "placeholder": "​",
            "style": "IPY_MODEL_52431bad23424c159123afa7fccacec1",
            "value": "tokenizer.json: 100%"
          }
        },
        "415d867582ce47b3b1166d1e67cd2de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a012cd5a40df49e5ad3a1c2586b7a815",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e99bdc34e462437382b77f3b5924a5ee",
            "value": 466021
          }
        },
        "9e1cb3cdfddb4751a66db5f453c25b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bc734be05a74e94b17632513e5ec1d3",
            "placeholder": "​",
            "style": "IPY_MODEL_15d4a84227924f56982f095839b0af92",
            "value": " 466k/466k [00:00&lt;00:00, 8.45MB/s]"
          }
        },
        "d66cc7a6b4ce4d06bb09056433ab8bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6331da87214343c19baa96eceba5bd36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52431bad23424c159123afa7fccacec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a012cd5a40df49e5ad3a1c2586b7a815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99bdc34e462437382b77f3b5924a5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bc734be05a74e94b17632513e5ec1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d4a84227924f56982f095839b0af92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1694ed63b02428f995d00418f0d2622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f88b1b56743f474ea06793dde7b80b1b",
              "IPY_MODEL_bf611667d28d4b6ca96d5349922db8ad",
              "IPY_MODEL_04f998ea0bea4cbdb148905dcb63fa73"
            ],
            "layout": "IPY_MODEL_2b0c825d961c4bafa430cefb67bb7ea5"
          }
        },
        "f88b1b56743f474ea06793dde7b80b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1099e354cf3340cf87c389011cb005de",
            "placeholder": "​",
            "style": "IPY_MODEL_29c1639bad014e72a79978c58f9fae45",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "bf611667d28d4b6ca96d5349922db8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c788142b952f4337b0f0b99eee9f4194",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_033abebe682d4d6aacb7ce02032fe581",
            "value": 239
          }
        },
        "04f998ea0bea4cbdb148905dcb63fa73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7148a9ed2d884178b09495cf4baf343e",
            "placeholder": "​",
            "style": "IPY_MODEL_fbca7c5751ad471f83c484550c631ba4",
            "value": " 239/239 [00:00&lt;00:00, 12.8kB/s]"
          }
        },
        "2b0c825d961c4bafa430cefb67bb7ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1099e354cf3340cf87c389011cb005de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c1639bad014e72a79978c58f9fae45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c788142b952f4337b0f0b99eee9f4194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "033abebe682d4d6aacb7ce02032fe581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7148a9ed2d884178b09495cf4baf343e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbca7c5751ad471f83c484550c631ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb4ab753ef7c409284708fcc754f6e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7064e6129a74deaa40229205725a409",
              "IPY_MODEL_40349699330e47e9bccda0a6afea2076",
              "IPY_MODEL_b4dd7441b600477e991bc902f0f6cadf"
            ],
            "layout": "IPY_MODEL_a4c962a207d94ae581215b3242e32d6e"
          }
        },
        "b7064e6129a74deaa40229205725a409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a389a0dd59df49b18a9135b992f16620",
            "placeholder": "​",
            "style": "IPY_MODEL_597b155503d5489a826c5ccfa2b1ee3c",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "40349699330e47e9bccda0a6afea2076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea6870641a24cef889a553f1526e828",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11d2893a7f06438db3e148080120bbc4",
            "value": 190
          }
        },
        "b4dd7441b600477e991bc902f0f6cadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e2d48923de44e9a95f0b63513acbb2",
            "placeholder": "​",
            "style": "IPY_MODEL_aeb24bf997334fa68783dd445439f46d",
            "value": " 190/190 [00:00&lt;00:00, 8.70kB/s]"
          }
        },
        "a4c962a207d94ae581215b3242e32d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a389a0dd59df49b18a9135b992f16620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597b155503d5489a826c5ccfa2b1ee3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ea6870641a24cef889a553f1526e828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d2893a7f06438db3e148080120bbc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0e2d48923de44e9a95f0b63513acbb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb24bf997334fa68783dd445439f46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YarongSong/GenAIPractice/blob/main/LangChain_Practice1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installing libraries and connect to LLMs"
      ],
      "metadata": {
        "id": "pNH6I4yNTvxk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W2OZYI5XlXXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd8b44e-352f-4fe0-a596-9e43da4d2d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/390.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/199.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU  \\\n",
        "  python-dotenv \\\n",
        "  langchain \\\n",
        "  langchain-community \\\n",
        "  openai \\\n",
        "  anthropic \\\n",
        "  langchain-openai \\\n",
        "  langchain-anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the API keys from the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZbN7ti31Adv",
        "outputId": "9f8a74d8-9ea0-4219-d55a-7b2595f0d2b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to OpenAI and Anthropic\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "llm_claude3 = ChatAnthropic(model='claude-3-opus-20240229')\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm_gpt4 = ChatOpenAI(model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "j8K_zG4D1HqA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that you can use the LLM\n",
        "#llm_claude3.invoke(\"What is LangChain?\").content\n",
        "llm_gpt4.invoke(\"What is LangChain?\").content"
      ],
      "metadata": {
        "id": "db48f5Ei1KSw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "db7ef822-22ad-42c3-9532-e0b8633a8706"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain is an open-source framework designed to help developers build applications that are powered by large language models (LLMs). It provides a structured approach to integrating LLMs with various data sources, APIs, and user inputs, enabling the creation of more complex and capable AI-driven applications. LangChain is particularly useful for tasks such as natural language processing, conversational agents, and any application that can benefit from the advanced language understanding and generation capabilities of LLMs.\\n\\nKey features of LangChain include:\\n\\n1. **Chain-of-Thought Reasoning**: LangChain allows developers to implement chain-of-thought reasoning in their applications, which helps the LLMs to perform more complex reasoning tasks by breaking them down into sequential steps.\\n\\n2. **Integration with Tools**: It provides connectors to integrate with various external tools and data sources, such as databases, APIs, and other third-party services, enabling LLMs to access and process a wide array of information.\\n\\n3. **Prompt Management**: LangChain offers utilities for managing and optimizing prompts to improve the performance and accuracy of LLMs in different contexts.\\n\\n4. **Customizable Pipelines**: Developers can create customizable pipelines to handle different stages of data processing, model interaction, and output generation, allowing for more tailored AI solutions.\\n\\n5. **Extensibility**: The framework is designed to be extensible, making it easier for developers to add new functionalities or integrate with other systems as required.\\n\\nLangChain is widely used in applications that require advanced language understanding, such as chatbots, virtual assistants, and other AI-driven communication interfaces.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_gpt4.invoke(\"What is the best weather in Seattle and why\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "xdBCMX1HCwnJ",
        "outputId": "997fd13c-1268-48b2-a7fa-b19846685ab2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The best weather in Seattle is generally considered to be during the late spring through early fall, particularly from June to September. During this time, the city experiences mild, pleasant temperatures and relatively low rainfall compared to the rest of the year. Here are some reasons why this period is considered the best:\\n\\n1. **Mild Temperatures**: Average high temperatures range from the upper 60s to the mid-70s Fahrenheit (around 20-25°C), which is comfortable for outdoor activities.\\n\\n2. **Lower Rainfall**: Seattle is known for its rainy weather, but the summer months are the driest. July and August, in particular, often have less than an inch of rain each, allowing for more sunny and clear days.\\n\\n3. **Longer Daylight Hours**: The summer months have long daylight hours, with the sun setting late in the evening, providing more time for outdoor activities and events.\\n\\n4. **Outdoor Activities and Events**: This period is ideal for enjoying Seattle's natural beauty, including parks, hiking trails, and water activities on Puget Sound. The city also hosts numerous festivals and events during the summer.\\n\\n5. **Vibrant Atmosphere**: With the good weather, there’s a vibrant atmosphere as locals and tourists alike take advantage of the pleasant conditions to explore the city, dine outdoors, and participate in cultural events.\\n\\nOverall, the combination of mild temperatures, low rainfall, and longer days makes late spring to early fall the most enjoyable time to visit Seattle for many people.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "THPbff716x42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic request using system and human/user message\n",
        "\n",
        "system_prompt=\"\"\"\n",
        "You explain things to people like they are five year olds.\n",
        "\"\"\"\n",
        "user_prompt=f\"\"\"\n",
        "What is LangChain?\n",
        "\"\"\"\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "import textwrap\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=system_prompt),\n",
        "    HumanMessage(content=user_prompt),\n",
        "]"
      ],
      "metadata": {
        "id": "sjfYGNmd1OfD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm_gpt4.invoke(messages)\n",
        "answer = textwrap.fill(response.content, width=100)"
      ],
      "metadata": {
        "id": "fIOYvhTR1u2X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer)"
      ],
      "metadata": {
        "id": "tulS9RsH1r86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9b5b0b-d479-4a13-c2c0-765288f54890"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, imagine you have a box of colorful building blocks, and each block is a different tool or\n",
            "toy. LangChain is like a special guidebook that helps you figure out how to connect and use these\n",
            "blocks together to build something cool, like a castle or a spaceship.  In the computer world,\n",
            "LangChain helps people connect different computer programs and smart helpers to work together. It’s\n",
            "like making sure all your toys play nicely together to create something amazing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Chains, Prompts and Loaders"
      ],
      "metadata": {
        "id": "jFugvpEcTpdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "mhgtPPEcN_dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple prompt template\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant that explains AI topics. Given the following input:\n",
        "{topic}\n",
        "Provide an explanation of the given topic.\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt from the prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=prompt_template,\n",
        ")\n"
      ],
      "metadata": {
        "id": "7NZqTnzIOL0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble the chain using the pipe operator \"|\", more on that later\n",
        "chain = prompt | llm_gpt4"
      ],
      "metadata": {
        "id": "PDwGnPSeP_q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"topic\":\"What is LangChain\"}).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "Wcb1W45pQEFJ",
        "outputId": "64085714-17dc-4461-edc5-0605304a30fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain is a framework designed to facilitate the development of applications that leverage large language models (LLMs). It provides a set of tools and abstractions that enable developers to build complex applications by combining LLMs with other data sources and computational resources. LangChain is particularly useful for creating applications that involve natural language processing tasks, such as chatbots, document analysis, and automated content generation.\\n\\nThe framework allows for the seamless integration of LLMs with various data stores, APIs, and user interfaces. By using LangChain, developers can build applications that not only rely on the capabilities of language models for understanding and generating text but also interact with external systems to retrieve and process information.\\n\\nKey features of LangChain include:\\n\\n1. **Modular Components**: LangChain provides modular components that can be easily assembled to create complex language-based applications. This modularity allows developers to customize and extend their applications as needed.\\n\\n2. **Data Integration**: The framework supports integration with various data sources, such as databases, APIs, and file systems, enabling applications to access and utilize external information.\\n\\n3. **Chain of Logic**: LangChain allows developers to define chains of logical operations that dictate how inputs are processed and outputs are generated. This chaining mechanism makes it easier to create workflows that involve multiple steps and dependencies.\\n\\n4. **Interoperability**: LangChain is designed to work with different LLMs and other AI tools, providing flexibility in choosing the best models and technologies for specific tasks.\\n\\nOverall, LangChain is a powerful tool for developers looking to harness the capabilities of large language models and build innovative applications that interact with both users and external systems.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1: Summarize the transcript of a YouTube video**"
      ],
      "metadata": {
        "id": "k4QEBy_VSYTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade --quiet  youtube-transcript-api"
      ],
      "metadata": {
        "id": "a6L3kvBFRasB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e087782-28f9-4544-b152-ae60cd7786ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/622.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/622.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Youtube Loader from the LangChain community\n",
        "\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "\n",
        "loader = YoutubeLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=AOEGOhkGtjI\", add_video_info=False\n",
        ")"
      ],
      "metadata": {
        "id": "FTkY3wQAOztq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the video transcript as documents\n",
        "docs=loader.load()"
      ],
      "metadata": {
        "id": "UuclzSCERocY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwFI1F1hneGi",
        "outputId": "9568b670-ddbb-47c2-cc8e-f108f7a67de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"so now we have Lama 3 from meta and this model is definitely going to be a GameChanger when it comes to analyzing data with llms here I have L 3 on gr cloud and not only are the text to SQL chains blazing fast they're also capable of generating quite Advanced SQL and almost on par with the high IQ llms if we Implement one additional tweak so in this video I'm going to show you how we can tweak the SQL chains to maximize the performance of Lama 3 we're going to have a look at some of the insights that Lama three is capable of extracting and finally I'm going to briefly discuss some of the implications for llm based data analysis on l.a. comom you can read about Lama 3 and some of the capabilities of the model you can see how the model compares to other popular llms specifically the 70b model that I'm going to be using in this video is compared to Gemini and CLA 3 Sunnet and there's also a link that lets you request access to Lama 3 but this is not what I'll be doing I'm going to be using Gro Cloud because it's the fastest and easiest way to get started using llama 3 and as you can see the 70b model is already available on gr Cloud so I'll just grab the API key and then I'm ready to build the SQL chains with L chain all right the first thing I'm going to do is I'm going to set up the cop notebook and pip install the required libraries then I'll connect to Bay and fetch the schema information from tables in a data set I'll be installing python. EnV to fetch the API Keys Lang chain Gro the Lang chain Gro connector and Google Cloud B quy then I have uploaded myv file with the API keys I have my Google cloud service account key DBQ key. jjon then I have two functions that extracts the schema information from bit query in a schema. py file and this is the same functions that I've been using in the earlier videos that lets me extract and feed the scheme information from bitre to the chain all right so I'm just going to load the environment variables and then I'm going to connect to biy and the data set I'm using is the same data set I used in the last video in the dashboard video it is an e-commerce data set with four tables customers orders products and customer taxs and the two functions in the schema. py file allows me to extract the schema information from the data set as you can see here so now let's connect to Lama 3 on Gro cloud and set set up the SQL chain using Lang chain expression language to connect to Lama 3 on groc cloud we import chat Gro from Lang chain grock and then we instantiate it with a model name in this case I'm using Lama 370b and the prom template will be injecting three things first I'll inject the schema information I'm extracting from the bit crate data set then I'm injecting the main question or the query and finally I'll be injecting a a message history and the message history is The Tweak I mentioned in the beginning so I'm going to have Lama 3 generate SQL code and then I'll use the bitr client to execute that SQL code and if there's an error I'm going to catch the error and feed it back to the chain and this allows me to make the chains self-correcting which is useful when we're dealing with a model that is of a low IQ the SQL chain is assembled in the usual way I'll use a runnable path through to to inject the schema information and to inject the messages of the message history that contains the errors then I use my prompt the language model and a string output passer and this is what we need to generate the SQL code from a prompt now let's move on to generate some insights with this setup I had difficulties having Lama 3 return clean executable SQL so I had to write a function that lets me extract the SQL code from the response and in this extract SQL function I'm simply using regex to extract the SQL from whatever the language model is returning to wrap it all up I'm creating a function that takes a prompt and a number of attempts as input and then it will generate the SQL using the Lang chain SQL chain and try to execute that SQL up to five times and whenever there's an error I'm going to collect the error and feed it back to the chain and try again and in this way the chain will be self-corrected ing because the llm will understand the error message okay so let's try this the first prompt I'm going to give L three is the following give me a list of the best customers including their rank their first name last name and email and the products they purchased and this one it got in the first attempt so the query executed successfully and we can then have a look at the data frame and this is essentially an audience that you could use for marketing purposes you normally create an audience like this in a customer data platform now let's try a different one I'll do a classical one show me the revenue generated in the last 30 days broken down by acquisition Channel and here you can see that the first attempt is unsuccessful it fails but feeding back the error message makes the second attempt successful and here we have Revenue broken down by acquisition source let's do another audience let's say I want the top 100 customers with the highest purchase frequency but with an under average aov and again we see that the first attempt fails and the second attempt is successful and here we only got the names let's say that we want to include the frequency and the aov as well to get the full overview and here we see that the first attempt fails the second attempt also fails but the third attempt is a success and here we have the full audience data frame with the purchase frequency and the average order value so this is very useful so we can use llama 3 for generating insights if we just implement this small tweak of catching the errors and feeding it back to the chain all right so what are the implications of this first of all we now know that with Lama 3 open source llms can be used to generate insights and this is very good news for privacy sensitive use cases so use cases where you want to feed sensitive customer data back to the llm and in real sensitive use cases you probably don't want to use gr Cloud you want to use Lama 3 locally this is also very good news for query heavy applications so text tosql applications can be query heavy if they're rolled out in a big organization so there's a cost consideration that might be worth looking into now Gro cloud is all about realtime gen inference so Lama 3 on gr cloud is going to be really useful for Consumer facing applications where speed is necessary finally I think it's pretty clear now that data pipelines dashboards reports and so on will be llm generated in the future and not so distant future so if you are a data analyst or data engineer you should really pay attention to this and learn this new technology all right that's it for now if you enjoyed this video I suggest you check out one of the other videos on generating SQL with llm chains thanks for watching\")]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript=docs[0].page_content"
      ],
      "metadata": {
        "id": "4RWjlF2RRrFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can now use the transcript in a chain\n",
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant that explains YT videos. Given the following video transcript:\n",
        "{video_transcript}\n",
        "Give a summary.\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"video_transcript\"],\n",
        "    template=prompt_template,\n",
        ")"
      ],
      "metadata": {
        "id": "kjtcIV1mR1FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm_gpt4"
      ],
      "metadata": {
        "id": "jXALdqNiSP3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that we can just feed the chain the docs without extracting the content as text\n",
        "\n",
        "chain.invoke({\"video_transcript\":docs}).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_6RbQR5ESUDR",
        "outputId": "cb08dac3-2e66-428c-834a-2126ece84c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The video discusses the use of the Lama 3 model from Meta, which is a significant advancement in data analysis using large language models (LLMs). The presenter demonstrates how to set up Lama 3 on Gro Cloud to generate SQL queries quickly and efficiently. The model is shown to be capable of producing advanced SQL queries, comparable to high IQ LLMs, with an additional tweak to enhance performance. The video outlines the process of setting up the environment, connecting to a dataset, and generating SQL chains using Lang Chain and Gro Cloud. It emphasizes the importance of error handling, where errors are fed back to the LLM to make the SQL chain self-correcting. The presenter also highlights the implications of Lama 3 for privacy-sensitive and query-heavy applications, suggesting that it could be particularly useful for consumer-facing applications due to its real-time inference capabilities. The video concludes by encouraging data analysts and engineers to explore this technology, as LLM-generated data pipelines, dashboards, and reports are likely to become more prevalent in the future.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2: Summarize an online-published scientific journal paper**"
      ],
      "metadata": {
        "id": "c_y2oAbLTCBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To use the WebBaseLoader you first need to install the langchain-community python package\n",
        "! pip install beautifulsoup4 requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm4BaVb3L2Pj",
        "outputId": "b55a2a85-5bf9-469b-a790-6b162c9ddc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.schema import Document\n",
        "\n",
        "\n",
        "# Fetch the webpage content\n",
        "url = \"https://www.nature.com/articles/s41598-017-07245-1\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "\n",
        "# Extract text (e.g., main content of the journal)\n",
        "text = soup.get_text()\n",
        "\n",
        "# Create a LangChain Document\n",
        "documents = [Document(page_content=text)]"
      ],
      "metadata": {
        "id": "zg2odHGjL_yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain"
      ],
      "metadata": {
        "id": "Mqqx7hO8PuL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a summarization chain\n",
        "chain = load_summarize_chain(llm_gpt4, chain_type=\"map_reduce\")\n",
        "\n",
        "# Run the summarization chain\n",
        "summary = chain.run(documents)\n",
        "answer = textwrap.fill(summary, width=100)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpF3YQxrPwxa",
        "outputId": "63b7090a-e14d-45b7-cfe3-b7080c403089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The study investigates the effect of chloride ions on the corrosion of ductile iron and carbon steel\n",
            "in soil environments. It finds that chloride ions significantly alter rust composition and corrosion\n",
            "kinetics, with low chloride levels causing general corrosion and high levels leading to localized\n",
            "corrosion. Chloride promotes the formation of specific rust products and maintains higher corrosion\n",
            "rates, especially initially. Carbon steel is more prone to chloride-induced corrosion than ductile\n",
            "iron. The findings emphasize the need to understand chloride's impact on corrosion for protecting\n",
            "underground pipelines, suggesting ductile iron's advantage in chloride-rich soils.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain"
      ],
      "metadata": {
        "id": "14-68lwFSsxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The create_stuff_documents_chain takes a list of docs and formats them all into a prompt\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant that explains AI topics. Given the following context:\n",
        "{context}\n",
        "Summarize what Llama 3 can do.\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\"],\n",
        "    template=prompt_template,\n",
        ")\n",
        "\n",
        "chain = create_stuff_documents_chain(llm_gpt4, prompt)"
      ],
      "metadata": {
        "id": "OYI-Ej1DSw9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#docs"
      ],
      "metadata": {
        "id": "vKAUFQElTPHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"context\": docs})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "Lb_RBPa2TSNf",
        "outputId": "fe7887d5-53f1-49bf-c659-c3af0b4e1367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Llama 3, developed by Meta, is a powerful language model that excels in data analysis using natural language processing. Key capabilities include:\\n\\n1. **Text-to-SQL Conversion:** Llama 3 can rapidly generate SQL queries from text prompts, facilitating the extraction of insights from data.\\n\\n2. **Advanced SQL Generation:** It is capable of creating sophisticated SQL queries, comparable to those generated by high-performing language models, especially with specific optimizations.\\n\\n3. **Error Correction:** The model can be made self-correcting by implementing a feedback loop that feeds error messages back into the process, enhancing its ability to produce correct SQL queries over multiple attempts.\\n\\n4. **Real-time Inference:** Running on platforms like Gro Cloud, Llama 3 supports real-time inference, making it suitable for consumer-facing applications requiring quick responses.\\n\\n5. **Privacy-sensitive Applications:** As an open-source LLM, Llama 3 can be used in scenarios where data privacy is crucial, allowing sensitive data to be processed without external cloud dependencies.\\n\\n6. **Scalability for Enterprise Use:** Llama 3 is beneficial for query-heavy applications in large organizations, providing a cost-effective solution for generating insights.\\n\\nOverall, Llama 3 is poised to revolutionize how data pipelines, dashboards, and reports are created, with significant implications for data analysts and engineers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. LCEL & Runnables"
      ],
      "metadata": {
        "id": "HDpbfZb1TknL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "summarize_prompt_template = \"\"\"\n",
        "You are a helpful assistant that summarizes AI concepts:\n",
        "{context}\n",
        "Summarize the context\n",
        "\"\"\"\n",
        "\n",
        "summarize_prompt = PromptTemplate.from_template(summarize_prompt_template)\n"
      ],
      "metadata": {
        "id": "HhaQozKlrnkC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "848txAD_o8kR",
        "outputId": "20f5d3b1-1488-48c2-c429-8fceb9729a6e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant that summarizes AI concepts:\\n{context}\\nSummarize the context\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Chain with the \"|\" operator"
      ],
      "metadata": {
        "id": "r264yXoiv7-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = summarize_prompt | llm_gpt4 | output_parser\n",
        "\n",
        "chain.invoke({\"context\": \"What is LangChain?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "NPx6Qz_bTiwz",
        "outputId": "bd0ab52d-d7bd-4b40-fa35-7fa0c392c804"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain is a framework designed to facilitate the development of applications that leverage large language models (LLMs). It provides a structured way to build complex applications by chaining together different components or modules, such as language models, APIs, and data processing tools, to perform tasks like natural language processing, information retrieval, and decision-making. LangChain aims to simplify the integration of LLMs into applications, enabling developers to focus on higher-level application logic rather than the low-level details of model deployment and management. It often includes functionalities for handling input/output, memory, and control flow, making it easier to create sophisticated AI-driven applications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the type of the chain\n",
        "print(type(chain)) # Should print <class 'langchain_core.runnables.base.RunnableSequence'>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW3dgnfXKU8r",
        "outputId": "ae9ce18d-5e31-48b4-e9c9-02069a059ae1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a RunnableLambda"
      ],
      "metadata": {
        "id": "ke-ycihtrxpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inject python functions into a chain with RunnableLambda\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "summarize_chain = summarize_prompt | llm_gpt4 | output_parser\n",
        "\n",
        "# Define a custom lambda function and wrap it in RunnableLambda\n",
        "length_lambda = RunnableLambda(lambda summary: f\"Summary length: {len(summary)} characters\")\n",
        "\n",
        "lambda_chain = summarize_chain\n",
        "\n",
        "lambda_chain.invoke({\"context\": \"What is LangChain?\"})"
      ],
      "metadata": {
        "id": "GEs1q_b6Kgs5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "28db4a61-0f39-44a5-f7cd-df8f2eeee684"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain is a framework designed to simplify the development of applications that leverage language models, such as OpenAI\\'s GPT-3. It provides a set of tools and abstractions that help developers build applications that can interact with language models more effectively and efficiently. LangChain is particularly focused on enabling applications that require complex, multi-step reasoning, integration with external data sources, and conversational capabilities.\\n\\nThe framework is built around the concept of \"chains,\" which allow developers to structure their applications in a modular way by connecting different components or steps in a sequence. These chains can handle tasks such as data retrieval, natural language understanding, and response generation. LangChain also supports the integration of various data sources and APIs, making it easier to build applications that can access and utilize external information.\\n\\nOverall, LangChain aims to streamline the process of creating advanced language model-based applications by providing a robust and flexible framework that can handle a wide range of use cases.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lambda_chain = summarize_chain | length_lambda\n",
        "\n",
        "lambda_chain.invoke({\"context\": \"What is LangChain?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nSASSSTEOI7G",
        "outputId": "30579e2d-84ab-4e3a-869f-56ab4f8c0100"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summary length: 1383 characters'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(lambda_chain.steps[-1])) # Should print <class 'langchain_core.runnables.base.RunnableLambda'>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-OhiwW33iiU",
        "outputId": "12b1b4c7-6c4f-45d8-e036-7b6e2de66824"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.runnables.base.RunnableLambda'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use function in chain without converting to RunnableLambda\n",
        "chain_with_function = summarize_chain |  (lambda summary: f\"Summary length: {len(summary)} characters\")"
      ],
      "metadata": {
        "id": "JI2Y4s7oUYOI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(chain_with_function.steps[-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZgqYfgj3hS1",
        "outputId": "c617daa8-d821-464e-8cb9-8220fac54d21"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.runnables.base.RunnableLambda'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_function.invoke({\"context\": \"What is LangChain?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q3x7H60speRq",
        "outputId": "1f7c33f7-0d69-441a-a287-145b9cc5f707"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summary length: 707 characters'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RunnablePassthrough as placeholder"
      ],
      "metadata": {
        "id": "75J0BqR3uKpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "summarize_chain = summarize_prompt | llm_gpt4 | output_parser\n",
        "\n",
        "# Create a RunnablePassthrough instance\n",
        "passthrough = RunnablePassthrough()\n",
        "\n",
        "# Create the sequence using the pipe operator with summarization and length calculation\n",
        "placeholder_chain = summarize_chain| passthrough | length_lambda\n",
        "\n",
        "placeholder_chain.invoke({\"context\": \"What is LangChain?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p6rAREimtqLi",
        "outputId": "8c20733a-fca6-44e5-ce29-cfc4c7d0c829"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summary length: 1744 characters'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(placeholder_chain.steps[-1]))  # Should print <class 'langchain_core.runnables.base.RunnableLambda'>\n",
        "print(type(placeholder_chain.steps[-2]))  # Should print <class 'langchain_core.runnables.passthrough.RunnablePassthrough'>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eZz4CEpviLa",
        "outputId": "70918d56-04da-4ce4-fd75-baf237b5b535"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.runnables.base.RunnableLambda'>\n",
            "<class 'langchain_core.runnables.passthrough.RunnablePassthrough'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RunnablePassthrough for assignment"
      ],
      "metadata": {
        "id": "Cc8VpIM4uQxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom lambda function to wrap the summary in a dictionary\n",
        "wrap_summary_lambda = RunnableLambda(lambda summary: {\"summary\": summary})\n",
        "\n",
        "# Create a RunnablePassthrough instance that assigns additional information\n",
        "assign_passthrough = RunnablePassthrough.assign(length=lambda x: len(x[\"summary\"]))\n",
        "\n",
        "# Create the summarization chain\n",
        "summarize_chain = summarize_prompt | llm_gpt4 | output_parser | wrap_summary_lambda\n",
        "\n",
        "# Create the full chain combining summarization and assign_passthrough\n",
        "assign_chain = summarize_chain | assign_passthrough\n",
        "\n",
        "# Use the chain\n",
        "assign_chain.invoke({\"context\": \"What is LangChain?\"})\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITVOr1PJ9u5z",
        "outputId": "cf211314-5da0-4aad-ce08-206d31032466"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'LangChain is a framework designed to facilitate the development of applications that leverage large language models (LLMs). It provides tools and abstractions to help developers build complex applications by integrating LLMs with various data sources, APIs, and user interfaces. LangChain focuses on several key areas:\\n\\n1. **Prompt Management**: It offers utilities to manage and optimize prompts for LLMs, enabling more effective interactions.\\n\\n2. **Chaining**: LangChain allows developers to create sequences of calls to an LLM or connect multiple LLMs together, enabling more complex workflows and decision-making processes.\\n\\n3. **Data Augmentation**: It supports the integration of external data sources, allowing applications to provide contextually relevant information to LLMs, improving their responses and capabilities.\\n\\n4. **Memory Management**: The framework includes tools for maintaining state or memory across interactions, which helps in creating more coherent and contextually aware applications.\\n\\n5. **Agent and Toolkits**: LangChain provides components for building intelligent agents that can interact with APIs or other software tools to perform tasks autonomously.\\n\\nOverall, LangChain aims to simplify the process of building powerful applications with LLMs by providing a structured approach to handling the complexities of prompt management, data integration, and workflow orchestration.',\n",
              " 'length': 1410}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(assign_chain.steps[-1])) # Should print <class 'langchain_core.runnables.passthrough.RunnableAssign'>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilA-25jYaITV",
        "outputId": "f4d28f5d-146a-4b63-c51b-753d679fcf75"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.runnables.passthrough.RunnableAssign'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using RunnableParallel"
      ],
      "metadata": {
        "id": "XhRfKg_Wws9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# Create the summarization chain\n",
        "summarize_chain = summarize_prompt | llm_gpt4 | output_parser\n",
        "\n",
        "# Create a RunnableParallel instance to handle summary and length in parallel\n",
        "parallel_runnable = RunnableParallel(\n",
        "    summary=lambda x: x,  # Passes the summary as is\n",
        "    length=lambda x: len(x)  # Calculates the length of the summary\n",
        ")\n",
        "\n",
        "# Combine the summarization chain with parallel runnable\n",
        "parallel_chain = summarize_chain | parallel_runnable\n",
        "\n",
        "parallel_chain.invoke({\"context\": \"What is LangChain?\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwgwh2Czzx75",
        "outputId": "ae23eedf-d383-47aa-ec00-0540a12a49ac"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'LangChain is an open-source framework designed to facilitate the development of applications using large language models (LLMs). It provides tools and abstractions to build complex applications by linking together different components that utilize LLMs. The framework is particularly focused on enabling applications that can perform tasks such as connecting to external data sources, managing interactions with multiple LLMs, and maintaining conversational context over time.\\n\\nKey features of LangChain include:\\n\\n1. **Chain Linking:** LangChain allows developers to create \"chains\" of operations or tasks that can be executed sequentially or in parallel, enabling more complex interactions with language models.\\n\\n2. **Integration with External Data:** LangChain provides mechanisms to connect LLMs with external data sources, allowing applications to query databases or fetch information from APIs and incorporate that data into model interactions.\\n\\n3. **Conversation Management:** The framework supports maintaining context across interactions, which is crucial for building conversational agents that can handle multi-turn dialogues effectively.\\n\\n4. **Customizability:** LangChain is designed to be flexible and customizable, allowing developers to tailor the behavior of language models to specific application requirements.\\n\\nOverall, LangChain aims to simplify the process of building robust, versatile applications that leverage the power of large language models by providing a structured way to manage and orchestrate complex workflows.',\n",
              " 'length': 1544}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the type of the last element in the chain\n",
        "print(type(parallel_chain.steps[-1]))  # Should print <class 'langchain_core.runnables.parallel.RunnableParallel'>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MSV99HovG1f",
        "outputId": "821b0c78-4b98-48ce-f62c-3030dcb98b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.runnables.base.RunnableParallel'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Retrievers & Splitters"
      ],
      "metadata": {
        "id": "2xnloFfrKdVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade --quiet  redis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtV7hn48HkHG",
        "outputId": "34066cae-dc96-402b-b1d1-f0785a8b8e09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/261.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/261.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Youtube Loader from the LangChain community\n",
        "\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "\n",
        "loader = YoutubeLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=AOEGOhkGtjI\", add_video_info=False\n",
        ")\n",
        "\n",
        "# Load the video transcript as documents\n",
        "docs=loader.load()"
      ],
      "metadata": {
        "id": "F-16JiI-w-y0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9oNaHe89j9j",
        "outputId": "95dc880d-d099-4f65-d8fb-d048d6e2c240"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"so now we have Lama 3 from meta and this model is definitely going to be a GameChanger when it comes to analyzing data with llms here I have L 3 on gr cloud and not only are the text to SQL chains blazing fast they're also capable of generating quite Advanced SQL and almost on par with the high IQ llms if we Implement one additional tweak so in this video I'm going to show you how we can tweak the SQL chains to maximize the performance of Lama 3 we're going to have a look at some of the insights that Lama three is capable of extracting and finally I'm going to briefly discuss some of the implications for llm based data analysis on l.a. comom you can read about Lama 3 and some of the capabilities of the model you can see how the model compares to other popular llms specifically the 70b model that I'm going to be using in this video is compared to Gemini and CLA 3 Sunnet and there's also a link that lets you request access to Lama 3 but this is not what I'll be doing I'm going to be using Gro Cloud because it's the fastest and easiest way to get started using llama 3 and as you can see the 70b model is already available on gr Cloud so I'll just grab the API key and then I'm ready to build the SQL chains with L chain all right the first thing I'm going to do is I'm going to set up the cop notebook and pip install the required libraries then I'll connect to Bay and fetch the schema information from tables in a data set I'll be installing python. EnV to fetch the API Keys Lang chain Gro the Lang chain Gro connector and Google Cloud B quy then I have uploaded myv file with the API keys I have my Google cloud service account key DBQ key. jjon then I have two functions that extracts the schema information from bit query in a schema. py file and this is the same functions that I've been using in the earlier videos that lets me extract and feed the scheme information from bitre to the chain all right so I'm just going to load the environment variables and then I'm going to connect to biy and the data set I'm using is the same data set I used in the last video in the dashboard video it is an e-commerce data set with four tables customers orders products and customer taxs and the two functions in the schema. py file allows me to extract the schema information from the data set as you can see here so now let's connect to Lama 3 on Gro cloud and set set up the SQL chain using Lang chain expression language to connect to Lama 3 on groc cloud we import chat Gro from Lang chain grock and then we instantiate it with a model name in this case I'm using Lama 370b and the prom template will be injecting three things first I'll inject the schema information I'm extracting from the bit crate data set then I'm injecting the main question or the query and finally I'll be injecting a a message history and the message history is The Tweak I mentioned in the beginning so I'm going to have Lama 3 generate SQL code and then I'll use the bitr client to execute that SQL code and if there's an error I'm going to catch the error and feed it back to the chain and this allows me to make the chains self-correcting which is useful when we're dealing with a model that is of a low IQ the SQL chain is assembled in the usual way I'll use a runnable path through to to inject the schema information and to inject the messages of the message history that contains the errors then I use my prompt the language model and a string output passer and this is what we need to generate the SQL code from a prompt now let's move on to generate some insights with this setup I had difficulties having Lama 3 return clean executable SQL so I had to write a function that lets me extract the SQL code from the response and in this extract SQL function I'm simply using regex to extract the SQL from whatever the language model is returning to wrap it all up I'm creating a function that takes a prompt and a number of attempts as input and then it will generate the SQL using the Lang chain SQL chain and try to execute that SQL up to five times and whenever there's an error I'm going to collect the error and feed it back to the chain and try again and in this way the chain will be self-corrected ing because the llm will understand the error message okay so let's try this the first prompt I'm going to give L three is the following give me a list of the best customers including their rank their first name last name and email and the products they purchased and this one it got in the first attempt so the query executed successfully and we can then have a look at the data frame and this is essentially an audience that you could use for marketing purposes you normally create an audience like this in a customer data platform now let's try a different one I'll do a classical one show me the revenue generated in the last 30 days broken down by acquisition Channel and here you can see that the first attempt is unsuccessful it fails but feeding back the error message makes the second attempt successful and here we have Revenue broken down by acquisition source let's do another audience let's say I want the top 100 customers with the highest purchase frequency but with an under average aov and again we see that the first attempt fails and the second attempt is successful and here we only got the names let's say that we want to include the frequency and the aov as well to get the full overview and here we see that the first attempt fails the second attempt also fails but the third attempt is a success and here we have the full audience data frame with the purchase frequency and the average order value so this is very useful so we can use llama 3 for generating insights if we just implement this small tweak of catching the errors and feeding it back to the chain all right so what are the implications of this first of all we now know that with Lama 3 open source llms can be used to generate insights and this is very good news for privacy sensitive use cases so use cases where you want to feed sensitive customer data back to the llm and in real sensitive use cases you probably don't want to use gr Cloud you want to use Lama 3 locally this is also very good news for query heavy applications so text tosql applications can be query heavy if they're rolled out in a big organization so there's a cost consideration that might be worth looking into now Gro cloud is all about realtime gen inference so Lama 3 on gr cloud is going to be really useful for Consumer facing applications where speed is necessary finally I think it's pretty clear now that data pipelines dashboards reports and so on will be llm generated in the future and not so distant future so if you are a data analyst or data engineer you should really pay attention to this and learn this new technology all right that's it for now if you enjoyed this video I suggest you check out one of the other videos on generating SQL with llm chains thanks for watching\")]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "-8_5WwpHDoFi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")"
      ],
      "metadata": {
        "id": "EMfIZb4YDoQJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_split = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "FkKhVCMcDoXX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFpE66iXDods",
        "outputId": "4e77a895-9bcb-4076-f80d-99bbd36919d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='so now we have Lama 3 from meta and this model is definitely going to be a GameChanger when it comes'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='when it comes to analyzing data with llms here I have L 3 on gr cloud and not only are the text to'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"are the text to SQL chains blazing fast they're also capable of generating quite Advanced SQL and\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='Advanced SQL and almost on par with the high IQ llms if we Implement one additional tweak so in'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"tweak so in this video I'm going to show you how we can tweak the SQL chains to maximize the\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"to maximize the performance of Lama 3 we're going to have a look at some of the insights that Lama\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"insights that Lama three is capable of extracting and finally I'm going to briefly discuss some of\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='discuss some of the implications for llm based data analysis on l.a. comom you can read about Lama'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='can read about Lama 3 and some of the capabilities of the model you can see how the model compares'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"the model compares to other popular llms specifically the 70b model that I'm going to be using in\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"to be using in this video is compared to Gemini and CLA 3 Sunnet and there's also a link that lets\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"a link that lets you request access to Lama 3 but this is not what I'll be doing I'm going to be\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I'm going to be using Gro Cloud because it's the fastest and easiest way to get started using llama\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"started using llama 3 and as you can see the 70b model is already available on gr Cloud so I'll\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"on gr Cloud so I'll just grab the API key and then I'm ready to build the SQL chains with L chain\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"chains with L chain all right the first thing I'm going to do is I'm going to set up the cop\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"to set up the cop notebook and pip install the required libraries then I'll connect to Bay and\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"connect to Bay and fetch the schema information from tables in a data set I'll be installing\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I'll be installing python. EnV to fetch the API Keys Lang chain Gro the Lang chain Gro connector\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='chain Gro connector and Google Cloud B quy then I have uploaded myv file with the API keys I have'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the API keys I have my Google cloud service account key DBQ key. jjon then I have two functions'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='have two functions that extracts the schema information from bit query in a schema. py file and'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"schema. py file and this is the same functions that I've been using in the earlier videos that lets\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='videos that lets me extract and feed the scheme information from bitre to the chain all right so'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"chain all right so I'm just going to load the environment variables and then I'm going to connect\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"going to connect to biy and the data set I'm using is the same data set I used in the last video in\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the last video in the dashboard video it is an e-commerce data set with four tables customers'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='tables customers orders products and customer taxs and the two functions in the schema. py file'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the schema. py file allows me to extract the schema information from the data set as you can see'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"set as you can see here so now let's connect to Lama 3 on Gro cloud and set set up the SQL chain\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='up the SQL chain using Lang chain expression language to connect to Lama 3 on groc cloud we import'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='cloud we import chat Gro from Lang chain grock and then we instantiate it with a model name in this'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"model name in this case I'm using Lama 370b and the prom template will be injecting three things\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"three things first I'll inject the schema information I'm extracting from the bit crate data set\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"bit crate data set then I'm injecting the main question or the query and finally I'll be injecting\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I'll be injecting a a message history and the message history is The Tweak I mentioned in the\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I mentioned in the beginning so I'm going to have Lama 3 generate SQL code and then I'll use the\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"then I'll use the bitr client to execute that SQL code and if there's an error I'm going to catch\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"I'm going to catch the error and feed it back to the chain and this allows me to make the chains\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"to make the chains self-correcting which is useful when we're dealing with a model that is of a low\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"that is of a low IQ the SQL chain is assembled in the usual way I'll use a runnable path through to\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='path through to to inject the schema information and to inject the messages of the message history'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the message history that contains the errors then I use my prompt the language model and a string'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='model and a string output passer and this is what we need to generate the SQL code from a prompt'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"code from a prompt now let's move on to generate some insights with this setup I had difficulties\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='I had difficulties having Lama 3 return clean executable SQL so I had to write a function that lets'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"function that lets me extract the SQL code from the response and in this extract SQL function I'm\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"SQL function I'm simply using regex to extract the SQL from whatever the language model is\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"language model is returning to wrap it all up I'm creating a function that takes a prompt and a\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='a prompt and a number of attempts as input and then it will generate the SQL using the Lang chain'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"the Lang chain SQL chain and try to execute that SQL up to five times and whenever there's an error\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"there's an error I'm going to collect the error and feed it back to the chain and try again and in\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='try again and in this way the chain will be self-corrected ing because the llm will understand the'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"will understand the error message okay so let's try this the first prompt I'm going to give L three\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='to give L three is the following give me a list of the best customers including their rank their'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='their rank their first name last name and email and the products they purchased and this one it got'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='and this one it got in the first attempt so the query executed successfully and we can then have a'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='we can then have a look at the data frame and this is essentially an audience that you could use'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='that you could use for marketing purposes you normally create an audience like this in a customer'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"this in a customer data platform now let's try a different one I'll do a classical one show me the\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='one show me the revenue generated in the last 30 days broken down by acquisition Channel and here'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='Channel and here you can see that the first attempt is unsuccessful it fails but feeding back the'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='feeding back the error message makes the second attempt successful and here we have Revenue broken'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"have Revenue broken down by acquisition source let's do another audience let's say I want the top\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='say I want the top 100 customers with the highest purchase frequency but with an under average aov'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='under average aov and again we see that the first attempt fails and the second attempt is'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"second attempt is successful and here we only got the names let's say that we want to include the\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='want to include the frequency and the aov as well to get the full overview and here we see that the'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='we see that the first attempt fails the second attempt also fails but the third attempt is a'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='third attempt is a success and here we have the full audience data frame with the purchase'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='with the purchase frequency and the average order value so this is very useful so we can use llama'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='so we can use llama 3 for generating insights if we just implement this small tweak of catching the'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='of catching the errors and feeding it back to the chain all right so what are the implications of'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='the implications of this first of all we now know that with Lama 3 open source llms can be used to'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='llms can be used to generate insights and this is very good news for privacy sensitive use cases so'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='use cases so use cases where you want to feed sensitive customer data back to the llm and in real'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"the llm and in real sensitive use cases you probably don't want to use gr Cloud you want to use\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='you want to use Lama 3 locally this is also very good news for query heavy applications so text'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"so text tosql applications can be query heavy if they're rolled out in a big organization so\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"big organization so there's a cost consideration that might be worth looking into now Gro cloud is\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='now Gro cloud is all about realtime gen inference so Lama 3 on gr cloud is going to be really'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='going to be really useful for Consumer facing applications where speed is necessary finally I think'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"finally I think it's pretty clear now that data pipelines dashboards reports and so on will be llm\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='so on will be llm generated in the future and not so distant future so if you are a data analyst or'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='a data analyst or data engineer you should really pay attention to this and learn this new'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content=\"and learn this new technology all right that's it for now if you enjoyed this video I suggest you\"),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='video I suggest you check out one of the other videos on generating SQL with llm chains thanks for'),\n",
              " Document(metadata={'source': 'AOEGOhkGtjI'}, page_content='chains thanks for watching')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"redis://default:6Sc3k3FJUlVVBF8lg8IUMp364h9qfPXG@redis-11669.c238.us-central1-2.gce.redns.redis-cloud.com:11669\"\n",
        "REDIS_URL=\"redis://default:your_redis_password@your_redis_host:your_redis_port\""
      ],
      "metadata": {
        "id": "ph5Y_KwAR6G2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REDIS_URL=\"redis://default:6Sc3k3FJUlVVBF8lg8IUMp364h9qfPXG@redis-11669.c238.us-central1-2.gce.redns.redis-cloud.com:11669\"\n",
        "REDIS_HOST=\"redis-11669.c238.us-central1-2.gce.redns.redis-cloud.com\"\n",
        "REDIS_PASSWORD=\"6Sc3k3FJUlVVBF8lg8IUMp364h9qfPXG\"\n",
        "REDIS_PORT=\"11669\""
      ],
      "metadata": {
        "id": "5yQG7bkSHBGl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "\n",
        "r = redis.Redis(\n",
        "  host=REDIS_HOST,\n",
        "  port=REDIS_PORT,\n",
        "  password=REDIS_PASSWORD)"
      ],
      "metadata": {
        "id": "sZoU-4ucDojx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check if we have the connection\n",
        "r.ping()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U_pMl4WDopo",
        "outputId": "6dd1e9c3-12e2-4085-c3fc-10461adee061"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.flushdb()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ACoTRLuL5CU",
        "outputId": "a4b73ebc-5dbc-40a2-c257-a2573c0b56a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade --quiet sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls9EpiPnyNJ4",
        "outputId": "8bcb1276-fc47-4722-a168-e26d13c1bb50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/268.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/268.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "58fffce02e874e709b6132e6601b41bb",
            "3a2132a6567b48e3a8980f89b4a41c91",
            "d327c394a1c74f3faaa2ec675b861385",
            "de2fd49fd32a4a7cb305cc62c9b0a137",
            "ec0ed66e4cf3479d929ce0003a0e37d7",
            "975f7adf0b504f3097ed080803f38341",
            "1758e1d8307d45b4a10d0f227982a8c2",
            "0f1ceea4599c4433ba50f6e4ce2fd5dc",
            "0569c7e21fdb48dc87fbe20c222b9f50",
            "541ab779a0c14f11980e73dc4d5f3f13",
            "b4d04dda527e453880b9524d7cf0a067",
            "f73889fe29e24e208973f64f7efa48a7",
            "82a626d87dfb4b37ac1072ebe11776fd",
            "723031d055804215b18a799301c2b90a",
            "9e30aee6a4c8464384843945e48a5d34",
            "9d647eb4bbcf46e58d47ce09768c8feb",
            "369b135edf4646119f7c6305c6f41952",
            "3272676949d34a5d832d4c5a8a986674",
            "cfab6216bfc94729bbfdca6f37a57f1a",
            "e72184a1c3af4f5bb989b03bde0ee7b5",
            "15bcd4d080d3433eb1aef84af6203d08",
            "25685c9c31b447e9abc0a4a8664212d3",
            "eb99c43b7df240968d14e8a1d6217042",
            "cfd567a09c9b44f59526a98c798de390",
            "37971867390a42ab911d1cda8e5339f4",
            "2bb549d4918f4943bd8657561e6ccc12",
            "38347aa1eb9147ee93876171aa9b6f55",
            "528af7db476a4dbe8606d14443951db6",
            "10d64c0421b1492cac13fc2fdda2bfc7",
            "3ffd888b127f41ea8c34a555cba5edc9",
            "3ae7595ad9f54ce093c01706be3100b0",
            "c558585e792e4aa1943156cb66ce3694",
            "7e19f9ed891c4388996cda3367ea8952",
            "e305a7962d984005a822103f1a540a76",
            "ac0303363b2747bf941a96ef922243e9",
            "83d7bd32d8604b22ba20c3731e9bcaa5",
            "3ff2bdb17bf4459eb49f9b7968c482ae",
            "03aa6c43fd1141c9b2010c794ba7379a",
            "7f37f52c0de14cb5bd81c868f3d9b834",
            "f26d9ed57a494cb08fce047cc9dfdb97",
            "23d3acbf571542c38365814c0b2d674c",
            "46d5d2278ee84137a8c84765438890dd",
            "7edb3b1bd106447f901d800776fe55f9",
            "4ef23d4f6bd54939a8d263e42ebe57b1",
            "2a893a623f5149d6a85c064a34032b2b",
            "de30de953f3b4e6cbdf0bc49f554fa29",
            "8d42a105610d498faa1afbc37d93c2ce",
            "752249c744954598b8a47b6a88893576",
            "9da42afab99c40b69d9f6d0266e2709e",
            "a1758ecdb397472eae343ca1922337e1",
            "718f888a671e4218a1a0b5126400833c",
            "814ae3a235c64fc78124461fd4913872",
            "119ab87eec3f4d12a0e1ef7cc4164538",
            "3c5c400aab194da4b7cb3738562e88a5",
            "e1267694501a4d04a22504ebdadfe6e2",
            "900cabeee1d64877972c3a7513c712ba",
            "2a81982ff498443a91f0e32f424ae8b5",
            "4ffac588e0a4424f9fb7bcfc585004b4",
            "37d651be5c2442b2a02fbe4fdc740be6",
            "500c6fd955214d5b9aa45698e5b980f5",
            "1afaeeda7b364c658ed2654ad3469d73",
            "2858ff07f607498689433d069dda8cb5",
            "cc6732cc383a41abadec6c778f049679",
            "722640f78ada4bd4a86d028a0026fcbe",
            "8d1c29b08c1746309a7e5d9bb97d75d9",
            "637fab710dc94a47bce90005d5ceb7a9",
            "be1a063491a443079abe0b531d36c9fb",
            "4dfc77ef26004bbf979992c83a5c85d0",
            "a6fc3407c87e4864abb0ace958b12221",
            "c74a9ac5368745079c819faeb702253f",
            "1fb0bf2bcc65498f9c6ca1561e24235f",
            "5a565f5bdaf345d5b8aa515fb66f65c5",
            "27d9c6c6e0c141d3bb3b4ecb17d51eed",
            "d58e6869bdec41a18e1921135f0193d9",
            "2963c1e526164ec78405105c77c192f8",
            "6094400a00074cdfb0d70a1942c0248d",
            "fa65b69d681140569de62278de13b500",
            "74caff8e240442e18de5b398354dc6cd",
            "134c614c2a3d4e5db7542e127ee439d6",
            "df8434993c02478187bc9605260f09ff",
            "34475919c842437e8f8eba0c0db36e35",
            "40444330d5a447628da4b47e5a889f17",
            "4e36ea0365e849388d1848049de4253f",
            "3588c067e03d4c6ab92e54460af46651",
            "6142048ea8e3411fa28ba154257632c0",
            "a64d2210a7fa4fbb8a5557bcadf4712e",
            "64c7a723d63d437594493b94c4cf7f86",
            "da6cf485a07a46ee91d042345abd477f",
            "a5c1cb9130dd4029bafbbaddb0dc2bc5",
            "640e351ac55640a4a9928a67fba1bf54",
            "415d867582ce47b3b1166d1e67cd2de7",
            "9e1cb3cdfddb4751a66db5f453c25b12",
            "d66cc7a6b4ce4d06bb09056433ab8bc4",
            "6331da87214343c19baa96eceba5bd36",
            "52431bad23424c159123afa7fccacec1",
            "a012cd5a40df49e5ad3a1c2586b7a815",
            "e99bdc34e462437382b77f3b5924a5ee",
            "2bc734be05a74e94b17632513e5ec1d3",
            "15d4a84227924f56982f095839b0af92",
            "a1694ed63b02428f995d00418f0d2622",
            "f88b1b56743f474ea06793dde7b80b1b",
            "bf611667d28d4b6ca96d5349922db8ad",
            "04f998ea0bea4cbdb148905dcb63fa73",
            "2b0c825d961c4bafa430cefb67bb7ea5",
            "1099e354cf3340cf87c389011cb005de",
            "29c1639bad014e72a79978c58f9fae45",
            "c788142b952f4337b0f0b99eee9f4194",
            "033abebe682d4d6aacb7ce02032fe581",
            "7148a9ed2d884178b09495cf4baf343e",
            "fbca7c5751ad471f83c484550c631ba4",
            "fb4ab753ef7c409284708fcc754f6e85",
            "b7064e6129a74deaa40229205725a409",
            "40349699330e47e9bccda0a6afea2076",
            "b4dd7441b600477e991bc902f0f6cadf",
            "a4c962a207d94ae581215b3242e32d6e",
            "a389a0dd59df49b18a9135b992f16620",
            "597b155503d5489a826c5ccfa2b1ee3c",
            "7ea6870641a24cef889a553f1526e828",
            "11d2893a7f06438db3e148080120bbc4",
            "f0e2d48923de44e9a95f0b63513acbb2",
            "aeb24bf997334fa68783dd445439f46d"
          ]
        },
        "id": "GnHpNle6Dou1",
        "outputId": "b79565c0-c8cd-430c-f3aa-22925f90294c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-a153ccf152c6>:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings()\n",
            "<ipython-input-23-a153ccf152c6>:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings()\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58fffce02e874e709b6132e6601b41bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f73889fe29e24e208973f64f7efa48a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb99c43b7df240968d14e8a1d6217042"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e305a7962d984005a822103f1a540a76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a893a623f5149d6a85c064a34032b2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "900cabeee1d64877972c3a7513c712ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be1a063491a443079abe0b531d36c9fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74caff8e240442e18de5b398354dc6cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5c1cb9130dd4029bafbbaddb0dc2bc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1694ed63b02428f995d00418f0d2622"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb4ab753ef7c409284708fcc754f6e85"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores.redis import Redis"
      ],
      "metadata": {
        "id": "x5qTlARpzlAs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rds = Redis.from_documents(\n",
        "    docs_split,\n",
        "    embeddings,\n",
        "    redis_url=REDIS_URL,\n",
        "    index_name=\"youtube\",\n",
        ")"
      ],
      "metadata": {
        "id": "hFrAYl_jDozt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rds.index_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mYvYqn8cDo4o",
        "outputId": "ba5ed2fe-d62f-4b7a-aa75-78f0fa54337e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'youtube'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = rds.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})"
      ],
      "metadata": {
        "id": "3HoxzPQrzs6D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"data analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnZ0mvWkzws1",
        "outputId": "83053357-c611-4d7a-d5ed-b2642622eda7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'id': 'doc:youtube:fb34544c783a4446905e7315f9fb251f', 'source': 'AOEGOhkGtjI'}, page_content=\"this in a customer data platform now let's try a different one I'll do a classical one show me the\"),\n",
              " Document(metadata={'id': 'doc:youtube:efaf8fafe45c4a3f8fa4c89997ec0b6b', 'source': 'AOEGOhkGtjI'}, page_content='a data analyst or data engineer you should really pay attention to this and learn this new'),\n",
              " Document(metadata={'id': 'doc:youtube:26ae842fc2fe4a1faa9116508015c216', 'source': 'AOEGOhkGtjI'}, page_content='we can then have a look at the data frame and this is essentially an audience that you could use'),\n",
              " Document(metadata={'id': 'doc:youtube:8e1b987ffc70475e8d935936ea49c6cc', 'source': 'AOEGOhkGtjI'}, page_content='discuss some of the implications for llm based data analysis on l.a. comom you can read about Lama'),\n",
              " Document(metadata={'id': 'doc:youtube:f292fd95a1564a049f1998c98bcfd207', 'source': 'AOEGOhkGtjI'}, page_content='the last video in the dashboard video it is an e-commerce data set with four tables customers'),\n",
              " Document(metadata={'id': 'doc:youtube:35d02eca7ed248e28725fcaa5584e495', 'source': 'AOEGOhkGtjI'}, page_content=\"going to connect to biy and the data set I'm using is the same data set I used in the last video in\"),\n",
              " Document(metadata={'id': 'doc:youtube:0da7c061c3e047f884e8d9b1d2b4ee98', 'source': 'AOEGOhkGtjI'}, page_content='with the purchase frequency and the average order value so this is very useful so we can use llama'),\n",
              " Document(metadata={'id': 'doc:youtube:1aeb61b47f8241babedccb50c16897b4', 'source': 'AOEGOhkGtjI'}, page_content='to give L three is the following give me a list of the best customers including their rank their'),\n",
              " Document(metadata={'id': 'doc:youtube:c6561c4a10cb453aa1a8169dd52bda24', 'source': 'AOEGOhkGtjI'}, page_content='when it comes to analyzing data with llms here I have L 3 on gr cloud and not only are the text to'),\n",
              " Document(metadata={'id': 'doc:youtube:22e3aaca29aa4fc7a7187617733d7d92', 'source': 'AOEGOhkGtjI'}, page_content=\"bit crate data set then I'm injecting the main question or the query and finally I'll be injecting\")]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Building a RAG Chain"
      ],
      "metadata": {
        "id": "kjRvkiDLKjIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "dUPzEJYIw_h7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "r6sZGnaMR7tS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\"context\": (lambda x: x[\"question\"]) | retriever,\n",
        "     \"question\": (lambda x: x[\"question\"])}\n",
        "    | prompt\n",
        "    | llm_gpt4\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "hhK2JQjgICGX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer=chain.invoke({\"question\":\"What can you do with LLama 3?\"})"
      ],
      "metadata": {
        "id": "gV2K6pb1R-0e"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EmMcbpIbBpFN",
        "outputId": "b87c5e8d-b4dd-4162-cafd-20be9d25a462"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You can use LLama 3 for generating insights, analyzing data, and maximizing performance. It is available on Gro Cloud, which provides a fast and easy way to get started with it.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Chain with a Tool"
      ],
      "metadata": {
        "id": "GIj3mBUBKlmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade --quiet  youtube_search"
      ],
      "metadata": {
        "id": "y0D6VWq9L23L"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import YouTubeSearchTool\n",
        "\n",
        "youtube_tool = YouTubeSearchTool()"
      ],
      "metadata": {
        "id": "zWo5gjMCLeIh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rabbitmetrics\n",
        "youtube_tool.run(\"Harry Potter\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mGhA0oZ1Ngav",
        "outputId": "b57f2cbc-a633-4406-a057-d8d60db6112a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['https://www.youtube.com/watch?v=Rve8m6voOLk&pp=ygUMSGFycnkgUG90dGVy', 'https://www.youtube.com/watch?v=SKTeMqRgQhE&pp=ygUMSGFycnkgUG90dGVy']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bind the YouTube tool to the LLM\n",
        "llm_with_tools = llm_gpt4.bind_tools([youtube_tool])"
      ],
      "metadata": {
        "id": "gTwJjbupMZma"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg =llm_with_tools.invoke(\"Harry Potter YT videos\")"
      ],
      "metadata": {
        "id": "IP2vlJ0B0uDW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfiebl0C23B0",
        "outputId": "088ff557-1eb4-42c1-c24f-8965cb938ab5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'youtube_search',\n",
              "  'args': {'query': 'Harry Potter'},\n",
              "  'id': 'call_mVCg4emtNR0sv9nFDaoFRPsK',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain=llm_with_tools | (lambda x: x.tool_calls[0][\"args\"][\"query\"]) | youtube_tool"
      ],
      "metadata": {
        "id": "D_yIhFdN04rF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"Find some Harry Potter videos on HALF-BLOOD PRINCE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nWOPj_Sj05dU",
        "outputId": "66e8f2e5-18b3-41c7-f2e4-06fd7dea8056"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['https://www.youtube.com/watch?v=tAiy66Xrsz4&pp=ygUeSGFycnkgUG90dGVyIEhhbGYtQmxvb2QgUHJpbmNl', 'https://www.youtube.com/watch?v=KuyYftjl4LI&pp=ygUeSGFycnkgUG90dGVyIEhhbGYtQmxvb2QgUHJpbmNl']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Building an Agent"
      ],
      "metadata": {
        "id": "rpsmuB_gK0n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade --quiet langchainhub"
      ],
      "metadata": {
        "id": "uiEjdI__2svv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent"
      ],
      "metadata": {
        "id": "uCltklw7kYgX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "prompt.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rbELzaL-6nh",
        "outputId": "4490a124-1892-4d8b-e153-bfb4e72ac33a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[youtube_tool]\n",
        "\n",
        "agent = create_tool_calling_agent(llm_gpt4, tools, prompt)\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "qQ0Gzyrn_ASh"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Find some langchain YT videos\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_rHfeiD_Ana",
        "outputId": "8d6180d4-98aa-46e3-f7bb-779679a7f1ca"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `youtube_search` with `{'query': 'langchain'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.youtube.com/watch?v=1bUy-1hGZpI&pp=ygUJbGFuZ2NoYWlu', 'https://www.youtube.com/watch?v=RoR4XJw8wIc&pp=ygUJbGFuZ2NoYWlu']\u001b[0m\u001b[32;1m\u001b[1;3mI found some YouTube videos about LangChain:\n",
            "\n",
            "1. [Video 1](https://www.youtube.com/watch?v=1bUy-1hGZpI&pp=ygUJbGFuZ2NoYWlu)\n",
            "2. [Video 2](https://www.youtube.com/watch?v=RoR4XJw8wIc&pp=ygUJbGFuZ2NoYWlu)\n",
            "\n",
            "You can check them out for more information on LangChain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Find some langchain YT videos',\n",
              " 'output': 'I found some YouTube videos about LangChain:\\n\\n1. [Video 1](https://www.youtube.com/watch?v=1bUy-1hGZpI&pp=ygUJbGFuZ2NoYWlu)\\n2. [Video 2](https://www.youtube.com/watch?v=RoR4XJw8wIc&pp=ygUJbGFuZ2NoYWlu)\\n\\nYou can check them out for more information on LangChain.'}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def transcribe_video(video_url:str) -> str:\n",
        "    \"Extract transcript from YT video\"\n",
        "    loader = YoutubeLoader.from_youtube_url(\n",
        "    video_url, add_video_info=False\n",
        "    )\n",
        "    docs=loader.load()\n",
        "    return docs"
      ],
      "metadata": {
        "id": "hB70blASlbo6"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [youtube_tool, transcribe_video]"
      ],
      "metadata": {
        "id": "obRRy20nmLm9"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "agent = create_tool_calling_agent(llm_gpt4, tools, prompt)\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "akG5YMcMmYmG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Find some Harry Potter YT videos\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc8VvpW8mfXi",
        "outputId": "75f7a48c-c168-40f1-a2e0-f32b9907a03d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `youtube_search` with `{'query': 'Harry Potter'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.youtube.com/watch?v=Rve8m6voOLk&pp=ygUMSGFycnkgUG90dGVy', 'https://www.youtube.com/watch?v=SKTeMqRgQhE&pp=ygUMSGFycnkgUG90dGVy']\u001b[0m\u001b[32;1m\u001b[1;3mHere are some Harry Potter videos on YouTube:\n",
            "\n",
            "1. [Video 1](https://www.youtube.com/watch?v=Rve8m6voOLk)\n",
            "2. [Video 2](https://www.youtube.com/watch?v=SKTeMqRgQhE)\n",
            "\n",
            "If you need more details or further assistance, feel free to ask!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Find some Harry Potter YT videos',\n",
              " 'output': 'Here are some Harry Potter videos on YouTube:\\n\\n1. [Video 1](https://www.youtube.com/watch?v=Rve8m6voOLk)\\n2. [Video 2](https://www.youtube.com/watch?v=SKTeMqRgQhE)\\n\\nIf you need more details or further assistance, feel free to ask!'}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zHMz8pmmpqT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}